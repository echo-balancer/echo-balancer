{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47aed77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import string\n",
    "from itertools import chain\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a441699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167408, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/census.csv')\n",
    "df['name'] = df['name'].map(str.title)\n",
    "\n",
    "\n",
    "# make it as a percentage\n",
    "races = ['pctwhite', 'pctblack', 'pctapi', 'pctaian', 'pct2prace', 'pcthispanic']\n",
    "df[races] = df[races] / 100\n",
    "\n",
    "df['other'] = df['pctaian'] + df['pct2prace']\n",
    "df = df.drop(['pctaian', 'pct2prace', 'count'], 1)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "248916a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pctwhite       0.774066\n",
       "pctblack       0.061102\n",
       "pctapi         0.055638\n",
       "pcthispanic    0.082398\n",
       "other          0.026673\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['pctwhite', 'pctblack', 'pctapi', 'pcthispanic', 'other']].sum() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ed6bbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('census.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e48091f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CENSUS = {}\n",
    "for _, row in df.iterrows():\n",
    "    CENSUS[row['name']] = {\n",
    "        'pctwhite': row['pctwhite'],\n",
    "        'pctblack': row['pctblack'],\n",
    "        'pctapi': row['pctapi'],\n",
    "        'pcthispanic': row['pcthispanic'],\n",
    "        'other': row['other']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "575193cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>other</th>\n",
       "      <th>pctapi</th>\n",
       "      <th>pctblack</th>\n",
       "      <th>pcthispanic</th>\n",
       "      <th>pctwhite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020725</td>\n",
       "      <td>0.006575</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.92345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020725</td>\n",
       "      <td>0.006575</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.92345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      other    pctapi  pctblack  pcthispanic  pctwhite\n",
       "0  0.020725  0.006575     0.028       0.0213   0.92345\n",
       "1  0.020725  0.006575     0.028       0.0213   0.92345"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([CENSUS['Kamper'], CENSUS['Kamper']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "3f94a669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pctwhite</th>\n",
       "      <th>pctblack</th>\n",
       "      <th>pctapi</th>\n",
       "      <th>pcthispanic</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name_length</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pctwhite  pctblack  pctapi  pcthispanic  other\n",
       "name_length                                                \n",
       "2                0.21      0.05    0.64         0.07   0.04\n",
       "3                0.47      0.07    0.34         0.08   0.04\n",
       "4                0.70      0.07    0.11         0.08   0.03\n",
       "5                0.76      0.07    0.07         0.08   0.03\n",
       "6                0.77      0.07    0.05         0.08   0.03\n",
       "7                0.79      0.06    0.04         0.08   0.03\n",
       "8                0.80      0.05    0.04         0.08   0.03\n",
       "9                0.82      0.04    0.04         0.07   0.02\n",
       "10               0.83      0.04    0.03         0.08   0.02\n",
       "11               0.79      0.03    0.05         0.10   0.02\n",
       "12               0.69      0.04    0.06         0.19   0.03\n",
       "13               0.54      0.03    0.04         0.36   0.02\n",
       "14               0.24      0.01    0.02         0.72   0.01\n",
       "15               0.57      0.01    0.35         0.06   0.01"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['name_length'] = df['name'].map(len)\n",
    "df.groupby('name_length')[['pctwhite', 'pctblack', 'pctapi', 'pcthispanic', 'other']].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "00735064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(text, n=2):\n",
    "    return [text[i:i+n] for i in range(len(text)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bac1b700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table(input_data, step=25, display_table=True, return_table=False):\n",
    "    \"\"\"Note: one should only use this function in Notebooks\n",
    "    stats summary table, similary to R function\"\"\"\n",
    "    if type(input_data) == pd.core.series.Series:\n",
    "        input_data = input_data.values\n",
    "    if input_data is None:\n",
    "        raise TypeError('input data cannot be null')\n",
    "    step = find_nearest([1, 2, 4, 5, 10, 20, 25], step)\n",
    "    y = np.arange(0, 100 + step, step)\n",
    "\n",
    "    x = np.percentile(input_data, y)\n",
    "    x = np.append(x, [np.mean(input_data), np.std(input_data), len(input_data)])\n",
    "    x = np.array([round(item, 3) for item in x])\n",
    "    y = np.append(y, ['Mean', 'Std', 'Count'])\n",
    "    tmp = pd.DataFrame([x], columns=y)\n",
    "    tmp.Count = tmp.Count.astype(int)\n",
    "\n",
    "    # display the table and set back the max_columns back to 20\n",
    "    if display_table:\n",
    "        if pd.get_option('max_columns') < 100:\n",
    "            pd.set_option('display.max_columns', 104)\n",
    "            display(tmp)\n",
    "            pd.set_option('display.max_columns', 20)\n",
    "        else:\n",
    "            display(tmp)\n",
    "\n",
    "    if return_table:\n",
    "        return tmp\n",
    "\n",
    "    \n",
    "def find_nearest(array, value):\n",
    "    \"\"\"helper function to return the closest value in an array\n",
    "    source: https://stackoverflow.com/questions/2566412/find-nearest-value-in-numpy-array\n",
    "    \"\"\"\n",
    "    if not isinstance(array, np.ndarray):\n",
    "        array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "55bca39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bi_gram'] = df['name'].map(get_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "f0410665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "644"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv = Counter(list(chain.from_iterable(df['bi_gram']))).most_common()\n",
    "len(kv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "c8ac47c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <th>8</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>14</th>\n",
       "      <th>16</th>\n",
       "      <th>18</th>\n",
       "      <th>20</th>\n",
       "      <th>22</th>\n",
       "      <th>24</th>\n",
       "      <th>26</th>\n",
       "      <th>28</th>\n",
       "      <th>30</th>\n",
       "      <th>32</th>\n",
       "      <th>34</th>\n",
       "      <th>36</th>\n",
       "      <th>38</th>\n",
       "      <th>40</th>\n",
       "      <th>42</th>\n",
       "      <th>44</th>\n",
       "      <th>46</th>\n",
       "      <th>48</th>\n",
       "      <th>50</th>\n",
       "      <th>52</th>\n",
       "      <th>54</th>\n",
       "      <th>56</th>\n",
       "      <th>58</th>\n",
       "      <th>60</th>\n",
       "      <th>62</th>\n",
       "      <th>64</th>\n",
       "      <th>66</th>\n",
       "      <th>68</th>\n",
       "      <th>70</th>\n",
       "      <th>72</th>\n",
       "      <th>74</th>\n",
       "      <th>76</th>\n",
       "      <th>78</th>\n",
       "      <th>80</th>\n",
       "      <th>82</th>\n",
       "      <th>84</th>\n",
       "      <th>86</th>\n",
       "      <th>88</th>\n",
       "      <th>90</th>\n",
       "      <th>92</th>\n",
       "      <th>94</th>\n",
       "      <th>96</th>\n",
       "      <th>98</th>\n",
       "      <th>100</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.02</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>28.6</td>\n",
       "      <td>36.0</td>\n",
       "      <td>45.32</td>\n",
       "      <td>53.0</td>\n",
       "      <td>59.08</td>\n",
       "      <td>74.9</td>\n",
       "      <td>89.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>141.02</td>\n",
       "      <td>160.6</td>\n",
       "      <td>188.06</td>\n",
       "      <td>215.52</td>\n",
       "      <td>251.12</td>\n",
       "      <td>292.64</td>\n",
       "      <td>352.0</td>\n",
       "      <td>434.52</td>\n",
       "      <td>527.76</td>\n",
       "      <td>600.16</td>\n",
       "      <td>670.4</td>\n",
       "      <td>749.0</td>\n",
       "      <td>868.32</td>\n",
       "      <td>970.8</td>\n",
       "      <td>1168.38</td>\n",
       "      <td>1317.24</td>\n",
       "      <td>1436.0</td>\n",
       "      <td>1521.72</td>\n",
       "      <td>1672.74</td>\n",
       "      <td>1932.88</td>\n",
       "      <td>2090.0</td>\n",
       "      <td>2497.4</td>\n",
       "      <td>2700.56</td>\n",
       "      <td>3038.72</td>\n",
       "      <td>3683.64</td>\n",
       "      <td>4072.92</td>\n",
       "      <td>4420.1</td>\n",
       "      <td>5245.8</td>\n",
       "      <td>5944.02</td>\n",
       "      <td>7407.64</td>\n",
       "      <td>10596.02</td>\n",
       "      <td>30430.0</td>\n",
       "      <td>1546.25</td>\n",
       "      <td>2828.788</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    2    4    6    8   10    12     14    16    18    20    22     24  \\\n",
       "0  1.0  1.0  2.0  3.0  5.0  7.0  11.0  13.02  18.0  23.0  28.6  36.0  45.32   \n",
       "\n",
       "     26     28    30    32     34     36      38     40      42      44  \\\n",
       "0  53.0  59.08  74.9  89.0  103.0  120.0  141.02  160.6  188.06  215.52   \n",
       "\n",
       "       46      48     50      52      54      56     58     60      62     64  \\\n",
       "0  251.12  292.64  352.0  434.52  527.76  600.16  670.4  749.0  868.32  970.8   \n",
       "\n",
       "        66       68      70       72       74       76      78      80  \\\n",
       "0  1168.38  1317.24  1436.0  1521.72  1672.74  1932.88  2090.0  2497.4   \n",
       "\n",
       "        82       84       86       88      90      92       94       96  \\\n",
       "0  2700.56  3038.72  3683.64  4072.92  4420.1  5245.8  5944.02  7407.64   \n",
       "\n",
       "         98      100     Mean       Std  Count  \n",
       "0  10596.02  30430.0  1546.25  2828.788    644  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table([i[1] for i in kv], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "6aa2a598",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NAME_LENGTH = 15\n",
    "CHAR_MAP = {k: (v + 1) for (k, v) in zip(string.ascii_lowercase[:26], np.arange(26))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a577e9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_gram_features = set([i[0] for i in kv if i[1] > 30 and i[1] < 2000])\n",
    "BI_GRAM_MAP = {k: v for (k, v) in zip(bi_gram_features, np.arange(len(bi_gram_features)))}\n",
    "df['bi_gram'] = df['bi_gram'].apply(lambda x: set([i for i in x if i in bi_gram_features]))\n",
    "len(bi_gram_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "242e7cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_count(name, n):\n",
    "    token_count_dict = {k: 0 for k in string.ascii_lowercase[:26]}\n",
    "    \n",
    "    if n == 1:\n",
    "        for char in name:\n",
    "            if char in token_count_dict:\n",
    "                token_count_dict[char] += 1\n",
    "                \n",
    "    if n == 2:\n",
    "        char_list = get_ngrams(name, 2)\n",
    "        char_counter = Counter([char[0] for char in char_list if char[0] in token_count_dict])\n",
    "        token_count_dict = {**token_count_dict, **dict(char_counter)}\n",
    "            \n",
    "    return token_count_dict        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "0aff07c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_featurization(name):\n",
    "    fi = np.zeros(len(CHAR_MAP) * 2 + 1) #MAX_NAME_LENGTH\n",
    "    \n",
    "    # unigram char count\n",
    "    fi[:len(CHAR_MAP)] = np.array(list(token_count(name, 1).values()))\n",
    "    \n",
    "    # bigram char count\n",
    "    fi[len(CHAR_MAP):len(CHAR_MAP)*2] = np.array(list(token_count(name, 2).values()))\n",
    "    \n",
    "    # length\n",
    "    name = name[:MAX_NAME_LENGTH]\n",
    "    name_length = len(name)\n",
    "    fi[len(CHAR_MAP) * 2] = name_length\n",
    "    \n",
    "#     # char map\n",
    "#     for i, char in enumerate(name):\n",
    "#         fi[len(CHAR_MAP) * 2 + 1 + i] = CHAR_MAP.get(char, 0)\n",
    "    \n",
    "    return fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "76538356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.9 s, sys: 188 ms, total: 4.09 s\n",
      "Wall time: 3.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = {}\n",
    "for n in df['name']:\n",
    "    features[n] = name_featurization(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "be77e8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167408"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "73241b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "13ce8629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4054efd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "dd925f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx = train_test_split(df.index, test_size=.2, random_state=42)\n",
    "race_to_predict = ['pctwhite', 'pctblack', 'pctapi', 'pcthispanic', 'other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "6b69ad2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 396 ms, sys: 29.9 ms, total: 426 ms\n",
      "Wall time: 425 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = np.stack([features[n] for n in df.loc[train_idx, 'name']])\n",
    "X_test = np.stack([features[n] for n in df.loc[test_idx, 'name']])\n",
    "\n",
    "df_truncate = (df[race_to_predict] > .3) * 1\n",
    "df_truncate = df_truncate[race_to_predict]\n",
    "y_train = df_truncate.loc[train_idx].to_numpy()\n",
    "y_test = df_truncate.loc[test_idx].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "f092c1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((133926, 53), (33482, 53))"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "23269c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((133926, 5), (33482, 5))"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "fed6b4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier# Using pipeline for applying logistic regression and one vs rest classifier\n",
    "LogReg_pipeline = Pipeline(\n",
    "    [('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "2461d219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 31s, sys: 1min 25s, total: 11min 57s\n",
      "Wall time: 2min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "ae72a44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    pctwhite       0.91      0.93      0.92     28272\n",
      "    pctblack       0.41      0.01      0.03      2215\n",
      "      pctapi       0.56      0.36      0.44      2049\n",
      " pcthispanic       0.62      0.44      0.52      2421\n",
      "       other       0.33      0.01      0.02       246\n",
      "\n",
      "   micro avg       0.88      0.80      0.84     35203\n",
      "   macro avg       0.57      0.35      0.38     35203\n",
      "weighted avg       0.83      0.80      0.80     35203\n",
      " samples avg       0.84      0.82      0.82     35203\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beimingliu/.pyenv/versions/3.6.1/envs/echo-chamber-meter/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/beimingliu/.pyenv/versions/3.6.1/envs/echo-chamber-meter/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_true = df.loc[test_idx]['pctapi'].round().to_numpy()\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=race_to_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "26085149",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "2c0593cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "b76f5f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 68, 32)            4096      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               82432     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 87,173\n",
      "Trainable params: 87,173\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(128, 32, input_length=68))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(len(race_to_predict), activation='softmax'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "2c554701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    pctwhite       0.89      0.95      0.92     28512\n",
      "    pctblack       0.30      0.08      0.12      2525\n",
      "      pctapi       0.53      0.25      0.34      2127\n",
      " pcthispanic       0.63      0.23      0.33      2523\n",
      "       other       0.24      0.05      0.08       326\n",
      "\n",
      "   micro avg       0.86      0.79      0.82     36013\n",
      "   macro avg       0.52      0.31      0.36     36013\n",
      "weighted avg       0.80      0.79      0.78     36013\n",
      " samples avg       0.84      0.82      0.82     36013\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beimingliu/.pyenv/versions/3.6.1/envs/echo-chamber-meter/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=race_to_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256defa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
